package typings.winkTokenizer.mod

import typings.std.RegExp
import scala.scalajs.js
import scala.scalajs.js.`|`
import scala.scalajs.js.annotation._

@js.native
trait Tokenizer extends js.Object {
  /**
    * Adds a regex for parsing a new type of token.
    * This regex can either be mapped to an existing tag or it allows creation of a new tag along with its finger print.
    * The uniqueness of the finger prints have to ensured by the user.
    * @param regex the new regular expression
    * @param tag tokens matching the regex will be assigned this tag
    * @param fingerprintCode
    */
  def addRegex(regex: RegExp, tag: String): Unit = js.native
  def addRegex(regex: RegExp, tag: String, fingerprintCode: String): Unit = js.native
  /**
    * Defines the configuration in terms of the types of token that will be extracted by tokenize() method.
    * Note by default, all types of tokens will be detected and tagged automatically.
    * @param config configuration object
    * @returns number of true parameters
    */
  def defineConfig(config: Config): Double = js.native
  /**
    * Returns the finger print of the tokens generated by the last call to tokenize().
    * A finger print is a string created by sequentially joining the unique code of each token's type.
    *
    * currency: 'r', email: 'e', emoji: 'j', emoticon: 'c',
    * hashtag: 'h', number: 'n', ordinal: 'o',
    * punctuation: token becomes fingerprint,
    * quoted_phrase: 'q', symbol: token becomes fingerprint,
    * time: 't', mention: 'm', url: 'u', word: 'w',
    * @return string of token types
    */
  def getTokensFP(): String = js.native
  /**
    * Tokenize a string
    * @param sentence to be tokenized
    * @returns tokens
    */
  def tokenize(sentence: String): js.Array[Token] = js.native
}

